{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning 2\n",
    "\n",
    "This year's Assignment will verse on predicting employee attrition. The dataset is available on Kaggle: [Employee Attrition competition](https://www.kaggle.com/competitions/playground-series-s3e3/data)\n",
    "\n",
    "* The goal is to predict whether an employee will leave the company or not (`Attrition` column, binary classification).\n",
    "* The dataset is artificially generated, but it is based on real data: [original data](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)\n",
    "    * Here you can find what each feature represents and their possible values.\n",
    "* You're given a training set and a test set. \n",
    "    * Perform your analysis, experiments and model selection on the training set, and don't touch the test set until you're ready to submit your predictions.\n",
    "    * You can save some data from the training set to use as a validation set, but you should not use the test set for this purpose.\n",
    "    * Once you're comfortable with the performance of your model on the training set, you can use the test set to get a final estimate of the performance of your model.\n",
    "    * The CSV file that you will submit, should contain the predictions of your model on the test set. This means that the CSV should contain as many rows as the test set, and a single column with the predictions (0 or 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EDA \n",
    "Delete Index Column & Obsolete Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.describe(include='all') #collection of information of the features - part 1 #attrition: 12% True, 88% False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.iloc[:,10:24].describe(include='all') #collection of information of the features - part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['EmployeeCount','Over18','StandardHours'], axis=1) #deletion of columns because they all have a domain of one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One Hot Encoding for Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data.select_dtypes(\"O\") #filter for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, drop = \"if_binary\") #deletion of excessive columns due to one-hot-encoding for columns with binary domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat_ohe = ohe.fit_transform(data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat_ohe = pd.DataFrame(data_cat_ohe, columns=ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.concat([data, data_cat_ohe], axis=1)\n",
    "data_full = data_full.drop(columns=data_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "      <th>AbsolutCorrValues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attrition</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <td>-0.194018</td>\n",
       "      <td>0.194018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.175006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverTime_Yes</th>\n",
       "      <td>0.173965</td>\n",
       "      <td>0.173965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.161044</td>\n",
       "      <td>0.161044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Attrition  AbsolutCorrValues\n",
       "Attrition              1.000000           1.000000\n",
       "StockOptionLevel      -0.194018           0.194018\n",
       "MaritalStatus_Single   0.175006           0.175006\n",
       "OverTime_Yes           0.173965           0.173965\n",
       "Age                   -0.161044           0.161044"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data_full.corr()[['Attrition']] #correlation matrix to identify features that have a high correlation with attrition\n",
    "corr ['AbsolutCorrValues'] = corr['Attrition'].abs()\n",
    "corr.sort_values(by = 'AbsolutCorrValues', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature set X and target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_full.drop(columns=['Attrition'])\n",
    "#X = data_full.loc[:,['StockOptionLevel','Age','JobInvolvement','TotalWorkingYears','JobLevel']]\n",
    "y = data_full['Attrition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    tp = cm[1, 1]\n",
    "    fn = cm[1, 0]\n",
    "    fp = cm[0, 1]\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred) # f1 = (2 * precision * sensitivity) / (precision + sensitivity)\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) # all positives #same as recall\n",
    "    specificity = tn / (tn + fp) # all negatives\n",
    "    precision = tp / (tp + fp) # all positive predictions\n",
    "     \n",
    "    acc = accuracy_score(y_true, y_pred) #acc = (tp+tn) / (tp+tn+fp+fn)\n",
    "       \n",
    "    print('confusion matrix:\\n',cm[0,],'\\tall negatives in test set =',(tn+fp),' \\n',cm[1,],'\\tall positives in test set=',(tp+fn),' \\n')\n",
    "    print(f\"f1-score: {f1:.2f}\\n\\nsensitivity: {sensitivity:.2f}\\nspecificity: {specificity:.2f}\\nprecision: {precision:.2f}\\n\\naccuracy: {acc:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model1: Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [316  54] \tall negatives in test set = 370  \n",
      " [36 14] \tall positives in test set= 50  \n",
      "\n",
      "f1-score: 0.24\n",
      "\n",
      "sensitivity: 0.28\n",
      "specificity: 0.85\n",
      "precision: 0.21\n",
      "\n",
      "accuracy: 0.79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#max_depth\n",
    "#min_samples_leaf\n",
    "#min_samples_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25, stratify = y)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state = 42, max_depth = 16, min_samples_leaf = 3, min_samples_split = 3) \n",
    "tree.fit(X_train, y_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "evaluation(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [366   4] \tall negatives in test set = 370  \n",
      " [46  4] \tall positives in test set= 50  \n",
      "\n",
      "f1-score: 0.14\n",
      "\n",
      "sensitivity: 0.08\n",
      "specificity: 0.99\n",
      "precision: 0.50\n",
      "\n",
      "accuracy: 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#max_depth: 16\n",
    "#min_samples_leaf: 1\n",
    "#min_samples_split: 2\n",
    "#n_estimators=100\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25, stratify = y)\n",
    "\n",
    "forest = RandomForestClassifier(random_state = 0, max_depth = 16, min_samples_leaf = 1, min_samples_split = 2, n_estimators=100) \n",
    "forest.fit(X_train, y_train)\n",
    "y_test_pred = forest.predict(X_test)\n",
    "\n",
    "evaluation(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [360  10] \tall negatives in test set = 370  \n",
      " [37 13] \tall positives in test set= 50  \n",
      "\n",
      "f1-score: 0.36\n",
      "\n",
      "sensitivity: 0.26\n",
      "specificity: 0.97\n",
      "precision: 0.57\n",
      "\n",
      "accuracy: 0.89\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catta\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, objective='binary:logistic')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "evaluation(y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
